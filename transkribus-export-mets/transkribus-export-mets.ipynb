{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting METS and PAGE XML files from a Transkribus collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "with open('./issue-parser-result.json') as issue_json:\n",
    "  issue_desc = json.load(issue_json)\n",
    "\n",
    "to_export_transkribus = issue_desc['document-id']\n",
    "#to_export_transkribus = 3289764 #4580229\n",
    "\n",
    "collectionId = re.search(r\"\\((\\w+)\\)\", issue_desc['source-collection']).group(0) [1:-1]\n",
    "\n",
    "#collectionId = 795736\n",
    "\n",
    "print(to_export_transkribus)\n",
    "print(collectionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collId = collectionId\n",
    "docId = to_export_transkribus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml_html_clean\n",
    "!pip install lxml[html_clean]\n",
    "!pip install requests-toolbelt\n",
    "\n",
    "import requests\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "import os\n",
    "from lxml import etree\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if secretsPath:\n",
    "    with open(secretsPath, 'r') as secretsFile:\n",
    "        secrets = json.loads(secretsFile.read())\n",
    "        for (k, v) in secrets.items():\n",
    "            os.environ[k] = v\n",
    "\n",
    "creds = json.loads(os.environ[\"TRANSKRIBUS_CREDENTIALS_SIMLER\"])\n",
    "\n",
    "s = requests.Session()\n",
    "s.post('https://transkribus.eu/TrpServer/rest/auth/login', data=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and transform METS, get PAGE XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- does it make sense to get mets files, too? \n",
    "\n",
    "http://transkribus.eu/TrpServer/rest/collections/{collId}/{id}/mets\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = s.get('https://transkribus.eu/TrpServer/rest/collections/'+ str(collId) +'/'+ str(docId) +'/mets')\n",
    "\n",
    "# Parse the METS XML content\n",
    "try:\n",
    "  tree = etree.fromstring(docs.content)\n",
    "  tree_unaltered = etree.fromstring(docs.content)\n",
    "\n",
    "  mets_xml = etree.tostring(tree, pretty_print=True).decode('utf-8')\n",
    "\n",
    "  # Find all xlink:href attributes in the namespace\n",
    "  for element in tree.xpath(\"//*[@*[local-name()='href' and namespace-uri()='http://www.w3.org/1999/xlink']]\"):\n",
    "      href_attribute = element.get('{http://www.w3.org/1999/xlink}href')\n",
    "      \n",
    "      # Find the parent ns3:file element\n",
    "      parent_file = element.getparent()\n",
    "      while parent_file is not None and parent_file.tag != '{http://www.loc.gov/METS/}file':\n",
    "          parent_file = parent_file.getparent()\n",
    "\n",
    "      if parent_file is not None:\n",
    "          file_id = parent_file.get('ID')\n",
    "          if file_id:\n",
    "            match = re.search(r'(\\d+)', file_id)\n",
    "            if match:\n",
    "              numeric_id = match.group(1)\n",
    "              new_href = \"page/\" + f\"{numeric_id.zfill(4)}_p\" + f\"{numeric_id.zfill(3)}.xml\" # Replace with your desired pattern using file_id if needed\n",
    "              element.set('{http://www.w3.org/1999/xlink}href', new_href)\n",
    "          else:\n",
    "              print(f\"Warning: Parent ns3:file element has no ID attribute for element: {etree.tostring(element)}\")\n",
    "      else:\n",
    "          print(f\"Warning: No parent ns3:file element found for element: {etree.tostring(element)}\")\n",
    "\n",
    "  print(etree.tostring(tree, pretty_print=True).decode())\n",
    "\n",
    "  mets_xml = etree.tostring(tree, pretty_print=True).decode('utf-8')\n",
    "\n",
    "  with open(\"./scratch/mets.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(mets_xml)\n",
    "\n",
    "  # Use XPath to find all ns3:file elements with mime type application/xml\n",
    "  namespace = {'ns2': 'http://www.w3.org/1999/xlink', 'ns3': 'http://www.loc.gov/METS/'}\n",
    "  for file_element in tree_unaltered.xpath(\"//ns3:file[@MIMETYPE='application/xml']\", namespaces=namespace):\n",
    "      # Find the ns2:href attribute within the ns3:FLocat child element\n",
    "      href = file_element.xpath(\"./ns3:FLocat/@ns2:href\", namespaces=namespace)\n",
    "\n",
    "      id_attribute = file_element.xpath(\"./@ID\")\n",
    "      if id_attribute:\n",
    "          # Extract the numeric part of the ID\n",
    "          match = re.search(r'(\\d+)', id_attribute[0])\n",
    "          if match:\n",
    "              numeric_id = match.group(1)\n",
    "              # Format the file name\n",
    "              formatted_filename = \"scratch/page/\" + f\"{numeric_id.zfill(4)}_p\" + f\"{numeric_id.zfill(3)}.xml\"\n",
    "              print(f\"ID: {id_attribute[0]}, Formatted filename: {formatted_filename}\")\n",
    "          else:\n",
    "              print(f\"Warning: Could not extract numeric ID from {id_attribute[0]}\")\n",
    "      else:\n",
    "          print(\"Warning: ID attribute not found for an element.\")\n",
    "\n",
    "      if href:\n",
    "          xml_url = href[0]\n",
    "          try:\n",
    "              xml_response = s.get(xml_url)\n",
    "              xml_response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
    "              xml_tree = etree.fromstring(xml_response.content)\n",
    "              print(etree.tostring(xml_tree, pretty_print=True).decode())\n",
    "              print(formatted_filename)\n",
    "              with open(formatted_filename, 'w', encoding=\"utf-8\") as xml_file:\n",
    "                  xml_file.write(etree.tostring(xml_tree, pretty_print=True).decode('utf-8'))\n",
    "\n",
    "          except requests.exceptions.RequestException as e:\n",
    "              print(f\"Error fetching XML from {xml_url}: {e}\")\n",
    "          except etree.XMLSyntaxError as e:\n",
    "              print(f\"Error parsing XML from {xml_url}: {e}\")\n",
    "      else:\n",
    "          print(\"ns2:href attribute not found in ns3:FLocat element.\")\n",
    "\n",
    "except etree.XMLSyntaxError as e:\n",
    "  print(f\"Error parsing XML: {e}\")\n",
    "  print(f\"Response content: {docs.content}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
